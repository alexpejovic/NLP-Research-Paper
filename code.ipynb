{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e510c92c-b2a5-475f-89a0-d09617217991",
   "metadata": {
    "id": "e510c92c-b2a5-475f-89a0-d09617217991"
   },
   "source": [
    "# Performance Experiments on BERTweet and RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wqhHwxHoOqbF",
   "metadata": {
    "id": "wqhHwxHoOqbF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install emoji\n",
    "!pip install datasets\n",
    "!pip install wget\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ab712-8dad-45da-b804-898797495911",
   "metadata": {
    "id": "916ab712-8dad-45da-b804-898797495911",
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### Import necessary libraries\n",
    "\n",
    "### Computational Libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "import transformers\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AutoTokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "### Data Interpretation and Retrieval\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import emoji\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "### Visualization\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "### For test_results storage\n",
    "import json\n",
    "\n",
    "### Miscellaneous\n",
    "import wget\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8797fb-1984-4e51-9356-10de95d71fa2",
   "metadata": {
    "id": "6e8797fb-1984-4e51-9356-10de95d71fa2"
   },
   "outputs": [],
   "source": [
    "####### General config\n",
    "\n",
    "### Set seed for reproducability\n",
    "SEED = 12\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "### Disable warnings\n",
    "transformers.logging.set_verbosity_error()\n",
    "datasets.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RAft9UQhozZ5",
   "metadata": {
    "id": "RAft9UQhozZ5"
   },
   "outputs": [],
   "source": [
    "###### Helper function for loading data\n",
    "def get_dataloader(inputs, masks, labels, batch_size=32):\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "    data = TensorDataset(inputs, masks, labels)\n",
    "    dataloader = DataLoader(data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a8561-6324-4846-a167-6b4e4ea4024e",
   "metadata": {
    "id": "a81a8561-6324-4846-a167-6b4e4ea4024e"
   },
   "outputs": [],
   "source": [
    "####### Load Datasets into Memory\n",
    "def load_datasets(max_length: int, batch_size: int):\n",
    "    \n",
    "    datasets = {\"roberta\": {\"glue\": dict(dict()), \"tweet\": dict(dict())},\n",
    "                \"tweet\": {\"glue\": dict(dict()), \"tweet\": dict(dict())}\n",
    "               }\n",
    "    \n",
    "    ### GLUE Datasets\n",
    "    for model in model_names:\n",
    "        for glue_set in glue_sets:\n",
    "            for split in dataset_splits:\n",
    "                dataset = load_dataset(\"glue\", glue_set, split=split)\n",
    "                \n",
    "                num_classes = dataset.info.features['label'].num_classes\n",
    "                \n",
    "                if model == 'roberta':\n",
    "                    tokenizer = roberta_tokenizer\n",
    "                else:\n",
    "                    tokenizer = bertweet_tokenizer\n",
    "\n",
    "                ### BERTweet Tokenization\n",
    "                tokenized = tokenizer(dataset['sentence'], add_special_tokens=True, padding='max_length', max_length=max_length, return_tensors='pt', truncation=True)\n",
    "                inputs = tokenized['input_ids']\n",
    "                masks = tokenized['attention_mask']\n",
    "                labels = np.asarray(dataset['label'])\n",
    "\n",
    "                if glue_set not in datasets[model]['glue']:\n",
    "                    datasets[model]['glue'][glue_set] = dict()\n",
    "                    datasets[model]['glue'][glue_set]['num_classes'] = num_classes\n",
    "                    \n",
    "                datasets[model]['glue'][glue_set][split] = get_dataloader(inputs, masks, labels, batch_size=batch_size)\n",
    "                print(\"Loaded dataset %s's %s split for GLUE benchmark for model %s\"%(glue_set, split, model))\n",
    "                \n",
    "    ### Twitter Datasets\n",
    "    for model in model_names:\n",
    "        for twitter_set in tweet_sets:\n",
    "            for split in dataset_splits:\n",
    "                dataset = load_dataset(\"tweet_eval\", twitter_set, split=split)\n",
    "                \n",
    "                num_classes = dataset.info.features['label'].num_classes\n",
    "                \n",
    "                if model == 'roberta':\n",
    "                    tokenizer = roberta_tokenizer\n",
    "                else:\n",
    "                    tokenizer = bertweet_tokenizer\n",
    "\n",
    "                ### BERTweet Tokenization\n",
    "                tokenized = tokenizer(dataset['text'], add_special_tokens=True, padding='max_length', max_length=max_length, return_tensors='pt', truncation=True)\n",
    "                inputs = tokenized['input_ids']\n",
    "                masks = tokenized['attention_mask']\n",
    "                labels = np.asarray(dataset['label'])\n",
    "\n",
    "                if twitter_set not in datasets[model]['tweet']:\n",
    "                    datasets[model]['tweet'][twitter_set] = dict()\n",
    "                    datasets[model]['tweet'][twitter_set]['num_classes'] = num_classes\n",
    "                    \n",
    "                datasets[model]['tweet'][twitter_set][split] = get_dataloader(inputs, masks, labels, batch_size=batch_size)\n",
    "                print(\"Loaded dataset %s's %s split for tweet_eval benchmark for model %s\"%(twitter_set, split, model))\n",
    "    \n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ZPkcsdyo7hH",
   "metadata": {
    "id": "2ZPkcsdyo7hH"
   },
   "outputs": [],
   "source": [
    "#### Function for loading models into memory\n",
    "def load_models(datasets, roberta=True, tweet=True):\n",
    "    models = {\"roberta\": {\"glue\": dict(), \"tweet\": dict()},\n",
    "                \"tweet\": {\"glue\": dict(), \"tweet\": dict()}\n",
    "             }\n",
    "    \n",
    "    ### Models for GLUE fine-tuning\n",
    "    for model_name in model_names:\n",
    "        for glue_set in glue_sets:\n",
    "            \n",
    "            if model_name == 'roberta' and roberta:\n",
    "                new_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=datasets[model_name]['glue'][glue_set]['num_classes'])\n",
    "            elif model_name == \"tweet\" and tweet:\n",
    "                new_model = RobertaForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=datasets[model_name]['glue'][glue_set]['num_classes'])\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            ### Disable gradient for params learned in pre-training\n",
    "            for name, param in new_model.named_parameters():\n",
    "                if 'classifier' not in name:\n",
    "                    param.requires_grad = False\n",
    "            \n",
    "            models[model_name]['glue'][glue_set] = new_model\n",
    "            if new_model is not None:\n",
    "              print(\"Loaded model %s for GLUE benchmark %s\"%(model_name, glue_set))\n",
    "            \n",
    "    ### Models for tweet-eval fine-tuning\n",
    "    for model_name in model_names:\n",
    "        for tweet_set in tweet_sets:\n",
    "            \n",
    "            if model_name == 'roberta' and roberta:\n",
    "                new_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=datasets[model_name]['tweet'][tweet_set]['num_classes'])\n",
    "            elif model_name == \"tweet\" and tweet:\n",
    "                new_model = RobertaForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=datasets[model_name]['tweet'][tweet_set]['num_classes'])\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            ### Disable gradient for params learned in pre-training\n",
    "            for name, param in new_model.named_parameters():\n",
    "                if 'classifier' not in name:\n",
    "                    param.requires_grad = False\n",
    "\n",
    "            models[model_name]['tweet'][tweet_set] = new_model\n",
    "            print(\"Loaded model %s for tweet_eval benchmark %s\"%(model_name, tweet_set))\n",
    "            \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dSKnQQ9lL2vK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSKnQQ9lL2vK",
    "outputId": "38db0fbf-8e37-4c14-e0c3-160df08b0fd6"
   },
   "outputs": [],
   "source": [
    "####### Instantiate Tokenizers\n",
    "bertweet_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n",
    "print(\"BERTweet Tokenizer successfully instantiated\")\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "print(\"RoBERTa Tokenizer successfully instantiated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PA4CCDhCLVvY",
   "metadata": {
    "id": "PA4CCDhCLVvY"
   },
   "outputs": [],
   "source": [
    "##### Declare what models and what datasets will be loaded into memory \n",
    "### Can not do all at once unless you have a LOT of System RAM\n",
    "### You must ensure models and datasets are loaded here in order to train\n",
    "\n",
    "### All possible models [\"roberta\", \"tweet\"]\n",
    "model_names = [\"tweet\"]\n",
    "\n",
    "### All possible glue tasks [\"cola\", \"sst2\"]\n",
    "glue_sets = [\"cola\"]\n",
    "\n",
    "### All possible tweet_eval tasks [\"emoji\", \"emotion\", \"hate\", \"irony\",\n",
    "#     \"offensive\", \"sentiment\", \"stance_abortion\", \"stance_atheism\",\n",
    "#     \"stance_climate\", \"stance_feminist\", \"stance_hillary\"]\n",
    "tweet_sets = [\"emoji\", \"emotion\", \"hate\"]\n",
    "\n",
    "### All possible dataset splits [\"train\", \"validation\", \"test\"]\n",
    "dataset_splits = [\"train\", \"validation\", \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669fcc70-dc8a-4bca-8535-e7506c77a64a",
   "metadata": {
    "id": "669fcc70-dc8a-4bca-8535-e7506c77a64a"
   },
   "outputs": [],
   "source": [
    "### Load datasets\n",
    "MAX_LEN = 30        # Maximum length of input tokens\n",
    "BATCH_SIZE = 32     # Batch size\n",
    "data = load_datasets(MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cEUO-bNApJHc",
   "metadata": {
    "id": "cEUO-bNApJHc"
   },
   "outputs": [],
   "source": [
    "### Load models\n",
    "### Ensure you re-run this cell when you want to test the same model again\n",
    "##  so you can reset the trained weights\n",
    "models = load_models(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0534978d-5866-413d-abc2-ae1f629c5a12",
   "metadata": {
    "id": "0534978d-5866-413d-abc2-ae1f629c5a12"
   },
   "outputs": [],
   "source": [
    "##### Functions for training models\n",
    "\n",
    "### Return accuracy from a set of predictions and true labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "### So time prints pretty\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "### Get optimizer and scheduler for model. We use AdamW for optimization\n",
    "##  and we linearly scale the learning rate to its max lr for the first 10% of\n",
    "##  training\n",
    "def get_optimizer_and_scheduler(model, total_steps, lr, weight_decay):\n",
    "    # Apply weight decay to all parameters beside the biases or LayerNorm weights\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            'weight_decay': weight_decay},\n",
    "        {\n",
    "            'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            'weight_decay': 0.0\n",
    "        }\n",
    "    ]\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        # Warmup learning rate for first 10% of training steps\n",
    "        num_warmup_steps=int(0.10 * total_steps), \n",
    "        num_training_steps=total_steps,\n",
    "    )\n",
    "    return optimizer, scheduler\n",
    "\n",
    "\n",
    "### Train the model, return the loss values and validation accuracies for\n",
    "##  each epoch and return the final test accuracy\n",
    "def train_model(model, epochs, train_dataloader, validation_dataloader,\n",
    "                test_dataloader, lr, weight_decay, device=\"cuda\"):\n",
    "    # Use GPU, if available\n",
    "    device = torch.device(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Setup optimizer and LR scheduler \n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    optimizer, scheduler = get_optimizer_and_scheduler(\n",
    "        model, total_steps, lr=lr, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    loss_values = []\n",
    "    eval_accs = []\n",
    "\n",
    "    for epoch in range(0, epochs):\n",
    "        t0 = time.time()\n",
    "\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        with tqdm(train_dataloader, unit=\"batch\") as train_pbar:\n",
    "            for batch in train_pbar:\n",
    "                train_pbar.set_description(f\"Training (epoch {epoch + 1})\")\n",
    "                b_input_ids = batch[0].to(device)\n",
    "                b_input_mask = batch[1].to(device)\n",
    "                b_labels = batch[2].to(device)\n",
    "\n",
    "                model.zero_grad()        \n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(\n",
    "                    input_ids=b_input_ids, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels\n",
    "                )\n",
    "                \n",
    "                # Calculate loss for this batch\n",
    "                loss = outputs.loss\n",
    "\n",
    "                # Add loss for total in epoch\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Calculate gradients\n",
    "                loss.backward()\n",
    "\n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "                # Update parameters based on gradient, learning rate, weight decay, etc.\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update the learning rate.\n",
    "                scheduler.step()\n",
    "\n",
    "        # Calculate the average loss over the training data.\n",
    "        avg_train_loss = total_loss / len(train_dataloader)            \n",
    "        \n",
    "        # Store the loss value.\n",
    "        loss_values.append(avg_train_loss)\n",
    "\n",
    "        print(\"  * Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  * Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "            \n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "        model.eval()\n",
    "\n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            \n",
    "            with torch.no_grad():        \n",
    "                # Forward pass\n",
    "                outputs = model(\n",
    "                    input_ids=b_input_ids, \n",
    "                    attention_mask=b_input_mask\n",
    "                )\n",
    "            \n",
    "            # Get the \"logits\" output\n",
    "            logits = outputs.logits\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "            # Calculate the accuracy for this batch of test sentences.\n",
    "            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "            # Accumulate the total accuracy.\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "            # Track the number of batches\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "        avg_eval_acc = eval_accuracy/nb_eval_steps\n",
    "        print(\"  * Accuracy: {0:.2f}\".format(avg_eval_acc))\n",
    "        print(\"  * Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "        eval_accs.append(avg_eval_acc)\n",
    "\n",
    "\n",
    "    ##### Obtain test accuracy\n",
    "    print(\"Running Testing...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "      b_input_ids, b_input_mask, b_labels = batch\n",
    "      \n",
    "      with torch.no_grad():        \n",
    "          # Forward pass\n",
    "          outputs = model(\n",
    "              input_ids=b_input_ids, \n",
    "              attention_mask=b_input_mask\n",
    "          )\n",
    "      \n",
    "      # Get the \"logits\" output\n",
    "      logits = outputs.logits\n",
    "      # Move logits and labels to CPU\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = b_labels.to('cpu').numpy()\n",
    "      # Calculate the accuracy for this batch of test sentences.\n",
    "      tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "      # Accumulate the total accuracy.\n",
    "      eval_accuracy += tmp_eval_accuracy\n",
    "      # Track the number of batches\n",
    "      nb_eval_steps += 1\n",
    "\n",
    "    test_acc = eval_accuracy/nb_eval_steps\n",
    "    print(\"  * Test Accuracy: {0:.2f}\".format(test_acc))\n",
    "    print(\"  * Testing took: {:}\".format(format_time(time.time() - t0)))\n",
    "      \n",
    "    print(\"Training complete!\")\n",
    "    return loss_values, eval_accs, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "krZwMqSp5jyZ",
   "metadata": {
    "id": "krZwMqSp5jyZ"
   },
   "outputs": [],
   "source": [
    "##### For storage for training results\n",
    "\n",
    "### Example object for what format json file should have when read\n",
    "test_results_example = {\n",
    "    \"roberta\": {\n",
    "        \"glue\": {\n",
    "            \"cola\": [],\n",
    "            \"sst2\": []\n",
    "        },\n",
    "        \"tweet\": {\n",
    "            \"emoji\": [],\n",
    "            \"emotion\": [],\n",
    "            \"hate\": [],\n",
    "            \"irony\": [],\n",
    "            \"offensive\": [],\n",
    "            \"sentiment\": [],\n",
    "            \"stance_abortion\": [],\n",
    "            \"stance_atheism\": [],\n",
    "            \"stance_climate\": [],\n",
    "            \"stance_feminist\": [],\n",
    "            \"stance_hillary\": [],\n",
    "        }\n",
    "    }, \n",
    "    \"tweet\": {\n",
    "        \"glue\": {\n",
    "            \"cola\": [],\n",
    "            \"sst2\": []\n",
    "        },\n",
    "        \"tweet\": {\n",
    "            \"emoji\": [],\n",
    "            \"emotion\": [],\n",
    "            \"hate\": [],\n",
    "            \"irony\": [],\n",
    "            \"offensive\": [],\n",
    "            \"sentiment\": [],\n",
    "            \"stance_abortion\": [],\n",
    "            \"stance_atheism\": [],\n",
    "            \"stance_climate\": [],\n",
    "            \"stance_feminist\": [],\n",
    "            \"stance_hillary\": [],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "### Write example to test_results.json if the file does not exist\n",
    "if not os.path.isfile(\"test_results.json\"):\n",
    "  with open('test_results.json', 'w') as f:\n",
    "    example_json = json.dumps(test_results_example, indent=2, sort_keys=True)\n",
    "    f.write(example_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d75347e-a5ee-46f7-9392-b3ad56e419a4",
   "metadata": {
    "id": "8d75347e-a5ee-46f7-9392-b3ad56e419a4"
   },
   "outputs": [],
   "source": [
    "#### Edit these variables to choose what model to run\n",
    "model_string = 'tweet'     # Choices: 'roberta', 'tweet'\n",
    "benchmark = 'glue'   # Choices: 'glue', 'tweet'\n",
    "\n",
    "task = 'cola'      # Choices if benchmark is 'glue':\n",
    "                        # 'cola', 'sst2'\n",
    "                      # Choices if benchmark is 'tweet':\n",
    "                        # \"emoji\", \"emotion\", \"hate\", \"irony\",\n",
    "                        # \"offensive\", \"sentiment\", \"stance_abortion\", \"stance_atheism\",\n",
    "                        # \"stance_climate\", \"stance_feminist\", \"stance_hillary\"\n",
    "\n",
    "\n",
    "dataloader_train = data[model_string][benchmark][task]['train']\n",
    "dataloader_val = data[model_string][benchmark][task]['validation']\n",
    "dataloader_test = data[model_string][benchmark][task]['test']\n",
    "model = models[model_string][benchmark][task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SpJNksSKKQYT",
   "metadata": {
    "id": "SpJNksSKKQYT"
   },
   "outputs": [],
   "source": [
    "### Run this to train with respect to variables in cell above\n",
    "lr = 5e-3\n",
    "weight_decay = 0.01\n",
    "epochs=7\n",
    "\n",
    "loss_vals, eval_accs, test_acc = train_model(\n",
    "    model=model,\n",
    "    epochs=epochs,\n",
    "    train_dataloader=dataloader_train,\n",
    "    validation_dataloader=dataloader_val,\n",
    "    test_dataloader=dataloader_test,\n",
    "    lr=lr,\n",
    "    weight_decay=weight_decay,\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299c772-00fe-4d80-b0d6-75fecb34498b",
   "metadata": {
    "id": "1299c772-00fe-4d80-b0d6-75fecb34498b"
   },
   "outputs": [],
   "source": [
    "### Write previous results to test_results file\n",
    "results = {\n",
    "    # \"training_losses\": loss_vals,\n",
    "    # \"validation_accs\": eval_accs,\n",
    "    \"test_acc\": test_acc,\n",
    "    \"hyperparams\": {\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"max_len\": MAX_LEN,\n",
    "        \"lr\": lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"epochs\": epochs,\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('test_results.json', 'r') as f:\n",
    "  file_data = json.load(f)\n",
    "  file_data[model_string][benchmark][task].append(results)\n",
    "  file_data = json.dumps(file_data, indent=4, sort_keys=True)\n",
    "\n",
    "with open('test_results.json', 'w') as f:\n",
    "  f.write(file_data)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "BERTweet-code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
